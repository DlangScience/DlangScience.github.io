<!DOCTYPE html><html><head>
<meta charset="UTF-8"/>
<title>Module dstats.tests</title>
<link rel="stylesheet" type="text/css" href="../styles/ddox.css"/>
<link rel="stylesheet" href="../prettify/prettify.css" type="text/css"/>
<script type="text/javascript" src="../scripts/jquery.js">/**/</script><script type="text/javascript" src="../scripts/ddox.js">/**/</script></head><body onload="setupDdox();"><nav id="main-nav"><noscript><p style="color: red">The search functionality needs JavaScript enabled</p></noscript><div id="symbolSearchPane" style="display: none"><form action="#" method="GET">
<input id="symbolSearch" type="text" name="q" placeholder="Search for symbols" autocomplete="off" onchange="performSymbolSearch(40);" onkeypress="this.onchange();" onpaste="this.onchange();" oninput="this.onchange();"/></form><ul id="symbolSearchResults" class="symbolList" style="display: none"></ul><script type="application/javascript" src="../symbols.js"></script><script type="application/javascript">var symbolSearchRootDir = "../";
$('#symbolSearchPane').show();</script></div><ul class="tree-view"><li class="tree-view "><div class="package "><a href="../dstats.html">dstats</a></div><ul class="tree-view"><li><div class="module "><a href="../dstats/alloc.html">alloc</a></div></li><li><div class="module "><a href="../dstats/base.html">base</a></div></li><li><div class="module "><a href="../dstats/cor.html">cor</a></div></li><li><div class="module "><a href="../dstats/distrib.html">distrib</a></div></li><li><div class="module "><a href="../dstats/infotheory.html">infotheory</a></div></li><li><div class="module "><a href="../dstats/kerneldensity.html">kerneldensity</a></div></li><li><div class="module "><a href="../dstats/pca.html">pca</a></div></li><li><div class="module "><a href="../dstats/random.html">random</a></div></li><li><div class="module "><a href="../dstats/regress.html">regress</a></div></li><li><div class="module "><a href="../dstats/sort.html">sort</a></div></li><li><div class="module "><a href="../dstats/summary.html">summary</a></div></li><li><div class="module selected"><a href="../dstats/tests.html">tests</a></div></li></ul></li></ul></nav><div id="main-contents"><h1>Module dstats.tests</h1><p>Hypothesis testing beyond simple CDFs.  All functions work with input
 ranges with elements implicitly convertible to double unless otherwise noted.
</p><section></section>

<section><section><h2>Author</h2>
<p>David Simcha
</p>
</section>
</section><section><h2>Functions</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Description</th></tr><tr><td><code><a id="binomialTest" class="["public"]" href="../dstats/tests/binomialTest.html">binomialTest</a><span class="decoration">(k, n, p)</span></code></td><td>Two-sided binomial test for whether P(success) == p.  The one-sided
alternatives are covered by dstats.distrib.binomialCDF and binomialCDFR.
k is the number of successes observed, n is the number of trials, p
is the probability of success under the null.
</td></tr><tr><td><code><a id="chiSquareContingency" class="["public"]" href="../dstats/tests/chiSquareContingency.html">chiSquareContingency</a><span class="decoration">(inputData)</span></code></td><td>Performs a Pearson's chi-square test on a contingency table of arbitrary
dimensions.  When the chi-square test is mentioned, this is usually the one
being referred to.  Takes a set of finite forward ranges, one for each column
in the contingency table.  These can be expressed either as a tuple of ranges
or a range of ranges.  Returns a P-value for the alternative hypothesis that
frequencies in each row of the contingency table depend on the column against
the null that they don't.
</td></tr><tr><td><code><a id="chiSquareFit" class="["public"]" href="../dstats/tests/chiSquareFit.html">chiSquareFit</a><span class="decoration">(observed, expected, countProp)</span></code></td><td>Performs a one-way Pearson's chi-square goodness of fit test between a range
of observed and a range of expected values.  This is a useful statistical
test for testing whether a set of observations fits a discrete distribution.
</td></tr><tr><td><code><a id="chiSquareObs" class="["public"]" href="../dstats/tests/chiSquareObs.html">chiSquareObs</a><span class="decoration">(x, y)</span></code></td><td>Given two vectors of observations of jointly distributed variables x, y, tests
the null hypothesis that values in x are independent of the corresponding
values in y.  This is done using Pearson's Chi-Square Test.  For a similar test
that assumes the data has already been tabulated into a contingency table, see
chiSquareContingency.
</td></tr><tr><td><code><a id="correlatedAnova" class="["public"]" href="../dstats/tests/correlatedAnova.html">correlatedAnova</a><span class="decoration">(dataIn)</span></code></td><td>Performs a correlated sample (within-subjects) ANOVA.  This is a
 generalization of the paired T-test to 3 or more treatments.  This
 function accepts data as either a tuple of ranges (1 for each treatment,
 such that a given index represents the same subject in each range) or
 similarly as a range of ranges.
</td></tr><tr><td><code><a id="dAgostinoK" class="["public"]" href="../dstats/tests/dAgostinoK.html">dAgostinoK</a><span class="decoration">(range)</span></code></td><td>A test for normality of the distribution of a range of values.  Based on
 the assumption that normally distributed values will have a sample skewness
 and sample kurtosis very close to zero.
</td></tr><tr><td><code><a id="falseDiscoveryRate" class="["public"]" href="../dstats/tests/falseDiscoveryRate.html">falseDiscoveryRate</a><span class="decoration">(pVals, dep)</span></code></td><td>Computes the false discovery rate statistic given a list of
p-values, according to Benjamini and Hochberg (1995) (independent) or
Benjamini and Yekutieli (2001) (dependent).  The Dependency parameter
controls whether hypotheses are assumed to be independent, or whether
the more conservative assumption that they are correlated must be made.
</td></tr><tr><td><code><a id="fisherExact" class="["public"]" href="../dstats/tests/fisherExact.html">fisherExact</a><span class="decoration">(contingencyTable, alt)</span></code></td><td>Fisher's Exact test for difference in odds between rows/columns
in a 2x2 contingency table.  Specifically, this function tests the odds
ratio, which is defined, for a contingency table c, as (c[0][0] * c[1][1])
 / (c[1][0] * c[0][1]).  Alternatives are Alt.less, meaning true odds ratio
&lt; 1, Alt.greater, meaning true odds ratio &gt; 1, and Alt.twoSided, meaning
true odds ratio != 1.
</td></tr><tr><td><code><a id="fisherExact" class="["public"]" href="../dstats/tests/fisherExact.html">fisherExact</a><span class="decoration">(contingencyTable, alt)</span></code></td><td>Convenience function.  Converts a dynamic array to a static one, then
calls the overload.
</td></tr><tr><td><code><a id="fishersMethod" class="["public"]" href="../dstats/tests/fishersMethod.html">fishersMethod</a><span class="decoration">(pVals)</span></code></td><td>Fisher's method of meta-analyzing a set of P-values to determine whether
 there are more significant results than would be expected by chance.
 Based on a chi-square statistic for the sum of the logs of the P-values.
</td></tr><tr><td><code><a id="friedmanTest" class="["public"]" href="../dstats/tests/friedmanTest.html">friedmanTest</a><span class="decoration">(dataIn)</span></code></td><td>The Friedman test is a non-parametric within-subject ANOVA.  It's useful
 when parametric assumptions cannot be made.  Usage is identical to
 correlatedAnova().
</td></tr><tr><td><code><a id="fTest" class="["public"]" href="../dstats/tests/fTest.html">fTest</a><span class="decoration">(data)</span></code></td><td>The F-test is a one-way ANOVA extension of the T-test to &gt;2 groups.
It's useful when you have 3 or more groups with equal variance and want
to test whether their means are equal.  Data can be input as either a
tuple or a range.  This may contain any combination of ranges of numeric
types, MeanSD structs and Summary structs.
</td></tr><tr><td><code><a id="gTestContingency" class="["public"]" href="../dstats/tests/gTestContingency.html">gTestContingency</a><span class="decoration">(inputData)</span></code></td><td>The G or likelihood ratio chi-square test for contingency tables.  Roughly
the same as Pearson's chi-square test (chiSquareContingency), but may be more
accurate in certain situations and less accurate in others.
</td></tr><tr><td><code><a id="gTestFit" class="["public"]" href="../dstats/tests/gTestFit.html">gTestFit</a><span class="decoration">(observed, expected, countProp)</span></code></td><td>The G or likelihood ratio chi-square test for goodness of fit.  Roughly
 the same as Pearson's chi-square test (chiSquareFit), but may be more
 accurate in certain situations and less accurate in others.  However, it is
 still based on asymptotic distributions, and is not exact. Usage is is
 identical to chiSquareFit.
</td></tr><tr><td><code><a id="gTestObs" class="["public"]" href="../dstats/tests/gTestObs.html">gTestObs</a><span class="decoration">(x, y)</span></code></td><td>Given two ranges of observations of jointly distributed variables x, y, tests
the null hypothesis that values in x are independent of the corresponding
values in y.  This is done using the Likelihood Ratio G test.  Usage is similar
to chiSquareObs.  For an otherwise identical test that assumes the data has
already been tabulated into a contingency table, see gTestContingency.
</td></tr><tr><td><code><a id="hochberg" class="["public"]" href="../dstats/tests/hochberg.html">hochberg</a><span class="decoration">(pVals)</span></code></td><td>Uses the Hochberg procedure to control the familywise error rate assuming
 that hypothesis tests are independent.  This is more powerful than
 Holm-Bonferroni correction, but requires the independence assumption.
</td></tr><tr><td><code><a id="holmBonferroni" class="["public"]" href="../dstats/tests/holmBonferroni.html">holmBonferroni</a><span class="decoration">(pVals)</span></code></td><td>Uses the Holm-Bonferroni method to adjust a set of P-values in a way that
 controls the familywise error rate (The probability of making at least one
 Type I error).  This is basically a less conservative version of
 Bonferroni correction that is still valid for arbitrary assumptions and
 controls the familywise error rate.  Therefore, there aren't too many good
 reasons to use regular Bonferroni correction instead.
</td></tr><tr><td><code><a id="kendallCorTest" class="["public"]" href="../dstats/tests/kendallCorTest.html">kendallCorTest</a><span class="decoration">(range1, range2, alt, exactThresh)</span></code></td><td>Tests the hypothesis that the Kendall Tau-b between two ranges is
different from 0.  Alternatives are Alt.less (kendallCor(range1, range2) &lt; 0),
Alt.greater (kendallCor(range1, range2) &gt; 0) and Alt.twoSided
(kendallCor(range1, range2) != 0).
</td></tr><tr><td><code><a id="kruskalWallis" class="["public"]" href="../dstats/tests/kruskalWallis.html">kruskalWallis</a><span class="decoration">(dataIn)</span></code></td><td>The Kruskal-Wallis rank sum test.  Tests the null hypothesis that data in
 each group is not stochastically ordered with respect to data in each other
 groups.  This is a one-way non-parametric ANOVA and can be thought of
 as either a generalization of the Wilcoxon rank sum test to &gt;2 groups or
 a non-parametric equivalent to the F-test.  Data can be input as either a
 tuple of ranges (one range for each group) or a range of ranges
 (one element for each group).
</td></tr><tr><td><code><a id="ksTest" class="["public"]" href="../dstats/tests/ksTest.html">ksTest</a><span class="decoration">(F, Fprime)</span></code></td><td>Performs a Kolmogorov-Smirnov (K-S) 2-sample test.  The K-S test is a
non-parametric test for a difference between two empirical distributions or
between an empirical distribution and a reference distribution.
</td></tr><tr><td><code><a id="ksTest" class="["public"]" href="../dstats/tests/ksTest.html">ksTest</a><span class="decoration">(Femp, F)</span></code></td><td>One-sample Kolmogorov-Smirnov test against a reference distribution.
Takes a callable object for the CDF of refernce distribution.
</td></tr><tr><td><code><a id="ksTestDestructive" class="["public"]" href="../dstats/tests/ksTestDestructive.html">ksTestDestructive</a><span class="decoration">(F, Fprime)</span></code></td><td>Same as ksTest, except sorts in place, avoiding memory allocations.
</td></tr><tr><td><code><a id="ksTestDestructive" class="["public"]" href="../dstats/tests/ksTestDestructive.html">ksTestDestructive</a><span class="decoration">(Femp, F)</span></code></td><td>Ditto.
</td></tr><tr><td><code><a id="levenesTest" class="["public"]" href="../dstats/tests/levenesTest.html">levenesTest</a><span class="decoration">(data)</span></code></td><td>Tests the null hypothesis that the variances of all groups are equal against
the alternative that heteroscedasticity exists.  data must be either a
tuple of ranges or a range of ranges.  central is an alias for the measure
of central tendency to be used.  This can be any function that maps a
forward range of numeric types to a numeric type.  The commonly used ones
are median (default) and mean (less robust).  Trimmed mean is sometimes
useful, but is currently not implemented in dstats.summary.
</td></tr><tr><td><code><a id="multinomialTest" class="["public"]" href="../dstats/tests/multinomialTest.html">multinomialTest</a><span class="decoration">(countsIn, proportions)</span></code></td><td>The exact multinomial goodness of fit test for whether a set of counts
fits a hypothetical distribution.  counts is an input range of counts.
proportions is an input range of expected proportions.  These are normalized
automatically, so they can sum to any value.
</td></tr><tr><td><code><a id="pairedTTest" class="["public"]" href="../dstats/tests/pairedTTest.html">pairedTTest</a><span class="decoration">(before, after, testMean, alt, confLevel)</span></code></td><td>Paired T test.  Tests the hypothesis that the mean difference between
corresponding elements of before and after is testMean.  Alternatives are
Alt.less, meaning the that the true mean difference (before[i] - after[i])
is less than testMean, Alt.greater, meaning the true mean difference is
greater than testMean, and Alt.twoSided, meaning the true mean difference is not
equal to testMean.
</td></tr><tr><td><code><a id="pairedTTest" class="["public"]" href="../dstats/tests/pairedTTest.html">pairedTTest</a><span class="decoration">(diffSummary, testMean, alt, confLevel)</span></code></td><td>Compute a paired T test directly from summary statistics of the differences
between corresponding samples.
</td></tr><tr><td><code><a id="pearsonCorTest" class="["public"]" href="../dstats/tests/pearsonCorTest.html">pearsonCorTest</a><span class="decoration">(range1, range2, alt, confLevel)</span></code></td><td>Tests the hypothesis that the Pearson correlation between two ranges is
different from some 0.  Alternatives are Alt.less
(pearsonCor(range1, range2) &lt; 0), Alt.greater (pearsonCor(range1, range2)
 0) and Alt.twoSided (pearsonCor(range1, range2) != 0).
</td></tr><tr><td><code><a id="pearsonCorTest" class="["public"]" href="../dstats/tests/pearsonCorTest.html">pearsonCorTest</a><span class="decoration">(cor, N, alt, confLevel)</span></code></td><td>Same as overload, but uses pre-computed correlation coefficient and sample
size instead of computing them.
</td></tr><tr><td><code><a id="runsTest" class="["public"]" href="../dstats/tests/runsTest.html">runsTest</a><span class="decoration">(obs, alt)</span></code></td><td>Wald-wolfowitz or runs test for randomness of the distribution of
elements for which positive() evaluates to true.  For example, given
a sequence of coin flips [H,H,H,H,H,T,T,T,T,T] and a positive() function of
"a == 'H'", this test would determine that the heads are non-randomly
distributed, since they are all at the beginning of obs.  This is done
by counting the number of runs of consecutive elements for which
positive() evaluates to true, and the number of consecutive runs for which
it evaluates to false.  In the example above, we have 2 runs.  These are the
block of 5 consecutive heads at the beginning and the 5 consecutive tails
at the end.
</td></tr><tr><td><code><a id="signTest" class="["public"]" href="../dstats/tests/signTest.html">signTest</a><span class="decoration">(before, after, alt)</span></code></td><td>Sign test for differences between paired values.  This is a very robust
 but very low power test.  Alternatives are Alt.less, meaning elements
 of before are typically less than corresponding elements of after,
 Alt.greater, meaning elements of before are typically greater than
 elements of after, and Alt.twoSided, meaning that there is a significant
 difference in either direction.
</td></tr><tr><td><code><a id="signTest" class="["public"]" href="../dstats/tests/signTest.html">signTest</a><span class="decoration">(data, mu, alt)</span></code></td><td>Similar to the overload, but allows testing for a difference between a
 range and a fixed value mu.
</td></tr><tr><td><code><a id="spearmanCorTest" class="["public"]" href="../dstats/tests/spearmanCorTest.html">spearmanCorTest</a><span class="decoration">(range1, range2, alt)</span></code></td><td>Tests the hypothesis that the Spearman correlation between two ranges is
different from some 0.  Alternatives are
Alt.less (spearmanCor(range1, range2) &lt; 0), Alt.greater (spearmanCor(range1, range2)
&gt; 0) and Alt.twoSided (spearmanCor(range1, range2) != 0).
</td></tr><tr><td><code><a id="studentsTTest" class="["public"]" href="../dstats/tests/studentsTTest.html">studentsTTest</a><span class="decoration">(data, testMean, alt, confLevel)</span></code></td><td>One-sample Student's T-test for difference between mean of data and
 a fixed value.  Alternatives are Alt.less, meaning mean(data) &lt; testMean,
 Alt.greater, meaning mean(data) &gt; testMean, and Alt.twoSided, meaning
 mean(data)!= testMean.
</td></tr><tr><td><code><a id="studentsTTest" class="["public"]" href="../dstats/tests/studentsTTest.html">studentsTTest</a><span class="decoration">(sample1, sample2, testMean, alt, confLevel)</span></code></td><td>Two-sample T test for a difference in means,
assumes variances of samples are equal.  Alteratives are Alt.less, meaning
mean(sample1) - mean(sample2) &lt; testMean, Alt.greater, meaning
mean(sample1) - mean(sample2) &gt; testMean, and Alt.twoSided, meaning
mean(sample1) - mean(sample2) != testMean.
</td></tr><tr><td><code><a id="welchAnova" class="["public"]" href="../dstats/tests/welchAnova.html">welchAnova</a><span class="decoration">(data)</span></code></td><td>Same as fTest, except that this test does not require the assumption of
equal variances.  In exchange it's slightly less powerful.
</td></tr><tr><td><code><a id="welchTTest" class="["public"]" href="../dstats/tests/welchTTest.html">welchTTest</a><span class="decoration">(sample1, sample2, testMean, alt, confLevel)</span></code></td><td>Two-sample T-test for difference in means.  Does not assume variances are equal.
Alteratives are Alt.less, meaning mean(sample1) - mean(sample2) &lt; testMean,
Alt.greater, meaning mean(sample1) - mean(sample2) &gt; testMean, and
Alt.twoSided, meaning mean(sample1) - mean(sample2) != testMean.
</td></tr><tr><td><code><a id="wilcoxonRankSum" class="["public"]" href="../dstats/tests/wilcoxonRankSum.html">wilcoxonRankSum</a><span class="decoration">(sample1, sample2, alt, exactThresh)</span></code></td><td>Computes Wilcoxon rank sum test statistic and P-value for
 a set of observations against another set, using the given alternative.
 Alt.less means that sample1 is stochastically less than sample2.
 Alt.greater means sample1 is stochastically greater than sample2.
 Alt.twoSided means sample1 is stochastically less than or greater than
 sample2.
</td></tr><tr><td><code><a id="wilcoxonSignedRank" class="["public"]" href="../dstats/tests/wilcoxonSignedRank.html">wilcoxonSignedRank</a><span class="decoration">(before, after, alt, exactThresh)</span></code></td><td>Computes a test statistic and P-value for a Wilcoxon signed rank test against
 the given alternative. Alt.less means that elements of before are stochastically
 less than corresponding elements of after.  Alt.greater means elements of
 before are stochastically greater than corresponding elements of after.
 Alt.twoSided means there is a significant difference in either direction.
</td></tr><tr><td><code><a id="wilcoxonSignedRank" class="["public"]" href="../dstats/tests/wilcoxonSignedRank.html">wilcoxonSignedRank</a><span class="decoration">(data, mu, alt, exactThresh)</span></code></td><td>Same as the overload, but allows testing whether a range is stochastically
 less than or greater than a fixed value mu rather than paired elements of
 a second range.
</td></tr></table></section><section><h2>Structs</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Description</th></tr><tr><td><code><a id="ConfInt" class="["public"]" href="../dstats/tests/ConfInt.html">ConfInt</a></code></td><td>A plain old data struct for returning the results of hypothesis tests
that also produce confidence intervals.  Contains, can implicitly convert
to, a TestRes.
</td></tr><tr><td><code><a id="GTestRes" class="["public"]" href="../dstats/tests/GTestRes.html">GTestRes</a></code></td><td>This struct is a subtype of TestRes and is used to return the results of
gTestContingency and gTestObs.  Due to the information theoretic interpretation
of the G test, it contains an extra field to return the mutual information
in bits.
</td></tr><tr><td><code><a id="RunsTest" class="["public"]" href="../dstats/tests/RunsTest.html">RunsTest</a></code></td><td>Runs test as in runsTest(), except calculates online instead of from stored
array elements.
</td></tr><tr><td><code><a id="TestRes" class="["public"]" href="../dstats/tests/TestRes.html">TestRes</a></code></td><td>A plain old data struct for returning the results of hypothesis tests.
</td></tr></table></section><section><h2>Enums</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Description</th></tr><tr><td><code><a id="Alt" class="["public"]" href="../dstats/tests/Alt.html">Alt</a></code></td><td>Alternative hypotheses.  Exact meaning varies with test used.
</td></tr><tr><td><code><a id="Dependency" class="["public"]" href="../dstats/tests/Dependency.html">Dependency</a></code></td><td>For falseDiscoveryRate.
</td></tr><tr><td><code><a id="Expected" class="["public"]" href="../dstats/tests/Expected.html">Expected</a></code></td><td>For chiSquareFit and gTestFit, is expected value range counts or proportions?
</td></tr></table></section><section><h2>Manifest constants</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Type</th><th>Description</th></tr><tr><td><a id="isArrayLike" class="["public"]" href="../dstats/tests/isArrayLike.html"><code>isArrayLike</code></a></td><td></td><td></td></tr><tr><td><a id="isSummary" class="["public"]" href="../dstats/tests/isSummary.html"><code>isSummary</code></a></td><td></td><td>Tests whether a struct/class has the necessary information for calculating
a T-test.  It must have a property .mean (mean), .stdev (stdandard deviation),
.var (variance), and .N (sample size).
</td></tr></table></section><section><h2>Aliases</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Type</th><th>Description</th></tr><tr><td><a id="chiSqrContingency" class="["public"]" href="../dstats/tests/chiSqrContingency.html"><code>chiSqrContingency</code></a></td><td><code class="prettyprint lang-d"></code></td><td></td></tr><tr><td><a id="chiSqrFit" class="["public"]" href="../dstats/tests/chiSqrFit.html"><code>chiSqrFit</code></a></td><td><code class="prettyprint lang-d"></code></td><td></td></tr><tr><td><a id="kcorTest" class="["public"]" href="../dstats/tests/kcorTest.html"><code>kcorTest</code></a></td><td><code class="prettyprint lang-d"></code></td><td></td></tr><tr><td><a id="pcorTest" class="["public"]" href="../dstats/tests/pcorTest.html"><code>pcorTest</code></a></td><td><code class="prettyprint lang-d"></code></td><td></td></tr><tr><td><a id="scorTest" class="["public"]" href="../dstats/tests/scorTest.html"><code>scorTest</code></a></td><td><code class="prettyprint lang-d"></code></td><td></td></tr></table></section><footer><table class="license-info"><tr><th>Authors</th><td></td></tr><tr><th>Copyright</th><td></td></tr><tr><th>License</th><td></td></tr></table><p class="faint">Generated using the DDOX documentation generator</p></footer></div></body></html>